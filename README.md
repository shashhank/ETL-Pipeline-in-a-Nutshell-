# ETL-Pipeline-in-a-Nutshell-
This project simulates an ETL pipeline, sourcing data from Kaggle, transforming it with Python, and analyzing business insights using SQL on SQL Server 


This project is a hands-on exploration of how an ETL (Extract, Transform, Load) pipeline works in a real-world scenario, simulating the data workflow that companies typically follow. I sourced my dataset via an API from Kaggle, a renowned platform for high-quality datasets. In the Extract phase, data was pulled from this API, followed by the Transform phase where I utilized Python (Pandas) to clean and process the data, ensuring accuracy and consistency. Finally, the data was loaded into a SQL Server data warehouse, pushed from Python to SQL Server using Docker on Azure Studio, to facilitate efficient analysis.

Once the data was ready, I tackled key business problems by writing SQL queries to gain actionable insights. These queries helped uncover trends and patterns, such as calculating total sales revenue, identifying the most frequently ordered products, and analyzing the most profitable states and segments. I also analyzed sales by month and segment, as well as identified top-performing regions, all of which contributed to a clearer understanding of business performance. By simulating this end-to-end ETL workflow and performing detailed analysis in SQL, Iâ€™ve gained valuable insights into how companies streamline their data pipelines to drive better decision-making and business strategies.







